# Explainable Instrument Classification: From MFCC Mean-Vector Models to CNNs on MFCC and Mel-Spectrograms with t-SNE and Grad-CAM Insights
## Overview
The project focuses on the classification of audio files of musical instruments using Deep Learning techniques.

The main objective is to develop a system capable of accurately recognizing and classifying musical instruments through the use of Convolutional Neural Networks (CNNs), by analyzing MFCC coefficients and Mel-Spectrograms.

An additional objective of the project is to study the behaviour of the Convolutional Neural Network using Mel-Spectrograms through explainability techniques.
## Dataset
The dataset is available [here](https://www.kaggle.com/datasets/abdulvahap/music-instrunment-sounds-for-classification)
## Code
- Classification using MFCCs: [Here](https://github.com/tommasosenatori/AIEA/blob/main/musical_instrument_classification_mfccs.ipynb)
- Classification using Mel-Spectograms: [Here](https://github.com/tommasosenatori/AIEA/blob/main/musical_instrument_classification_mel-spectograms.ipynb)
- MFCC MEAN and t-SNE: [Here](https://github.com/tommasosenatori/AIEA/blob/main/musical_instrument_classification_mfcc_mean-tsne.ipynb)
## Authors
- Tommaso Senatori
- Daniela Nardone
